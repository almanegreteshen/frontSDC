{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: BIM e Innovaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pandas as pd\n",
    "from itertools import zip_longest as zip\n",
    "from itertools import count\n",
    "import numpy as np\n",
    "import codecs\n",
    "\n",
    "## A. Writing Json file with format \n",
    "def write_json_UTF8(jsonDir, name_file):\n",
    "    with open(name_file, 'w') as outfile:\n",
    "        json.dump(jsonDir, outfile, ensure_ascii=False)\n",
    "    with codecs.open(name_file, 'r', encoding = \"iso-8859-1\") as file:\n",
    "          lines = file.read()\n",
    "    with codecs.open(name_file, 'w', encoding = 'utf8') as file:\n",
    "          file.write(lines)\n",
    "    print(\"CREATED: \", name_file)\n",
    "    \n",
    "## B. Fixing numbers             \n",
    "def repair_num(value):\n",
    "    try:\n",
    "        aux = float(value)\n",
    "    except:\n",
    "        \"Existe algun signo\"\n",
    "        aux = \"\"\n",
    "        for letra in str(value):\n",
    "\n",
    "            if letra.isdigit():\n",
    "                aux = aux+letra\n",
    "            elif letra == \".\":\n",
    "                aux = aux+letra\n",
    "        if aux == \"\":\n",
    "            pass\n",
    "\n",
    "    return float(aux)\n",
    "\n",
    "## C. Formating Json\n",
    "def DataToJson(df, varible_v, variable_meaning, reg_name, toolTip_v, toolTip_mening, norm=False):\n",
    "    globalDir = {}\n",
    "    anioInit = -999\n",
    "    listData = []\n",
    "    dirData = {}\n",
    "    initDir = True\n",
    "    df_norm = None\n",
    "    if norm:\n",
    "        df_copy = df.copy()\n",
    "        df_norm = (df_copy[varible_v]-df_copy[varible_v].min()) / \\\n",
    "            (df_copy[varible_v].max()-df_copy[varible_v].min())\n",
    "\n",
    "    for i, anio, mes, var_value in zip(count(), df[\"anio\"], df[\"mesSTR\"], df[varible_v]):\n",
    "        try:\n",
    "            anio = int(anio)\n",
    "        except:\n",
    "            print(\"set:\", anio)\n",
    "            listData.append(dirData)\n",
    "            break\n",
    "\n",
    "        # Si todas son nan no sirve\n",
    "        L = 0\n",
    "        for index, v_reg in enumerate(varible_v):\n",
    "            if str(df[v_reg].values[i]) == \"nan\":\n",
    "                L = L+1\n",
    "        if L == len(varible_v):\n",
    "            print(\"allNone\", anio)\n",
    "            continue\n",
    "\n",
    "        if anioInit < anio:\n",
    "            if anioInit > 0:\n",
    "                listData.append(dirData)\n",
    "                dirData = {}\n",
    "                initDir = True\n",
    "\n",
    "        if initDir:\n",
    "            dirData[\"anio\"] = anio\n",
    "            dirData[\"regiones\"] = {}\n",
    "            for index, v_reg in enumerate(varible_v):\n",
    "                dirData[\"regiones\"][reg_name[index]] = {\"meses\": {}}\n",
    "\n",
    "            initDir = False\n",
    "\n",
    "        for index, v_reg in enumerate(varible_v):\n",
    "            dirData[\"regiones\"][reg_name[index]][\"meses\"][mes] = {}\n",
    "\n",
    "        for index, v_reg in enumerate(varible_v):\n",
    "\n",
    "            # dirData[\"regiones\"][reg_name[index]][\"meses\"][mes][\"indicar_principal\"]=df[v_reg].values[i]\n",
    "            if norm:\n",
    "                dirData[\"regiones\"][reg_name[index]][\"meses\"][mes][variable_meaning[index]] = round(\n",
    "                    float(df_norm[v_reg].values[i]), 4)\n",
    "                if (df_norm[v_reg].values[i]) == \"nan\":\n",
    "                    del dirData[\"regiones\"][reg_name[index]][\"meses\"][mes]\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                # si no hay data\n",
    "                data_value = repair_num(df[v_reg].values[i])\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    data_value=float(df[v_reg].values[i])\n",
    "                except:\n",
    "                    \"Existe algun signo\"\n",
    "                    aux=\"\"\n",
    "                    for letra in str(df[v_reg].values[i]):\n",
    "                        if letra.isdigit():\n",
    "                            aux=aux+letra\n",
    "                        elif letra ==\".\":\n",
    "                            aux=aux+letra\n",
    "                            \n",
    "                    data_value=float(aux)\n",
    "                \n",
    "                \"\"\"\n",
    "\n",
    "                if str(data_value).lower() == \"nan\" or len(str(data_value).lower()) == 0:\n",
    "                    data_value = 0\n",
    "                if data_value - int(data_value) > 0.0001:\n",
    "                    data_value = round(data_value, 1)\n",
    "                else:\n",
    "                    data_value = int(data_value)\n",
    "                dirData[\"regiones\"][reg_name[index]\n",
    "                                    ][\"meses\"][mes][variable_meaning[index]] = data_value\n",
    "                if (df[v_reg].values[i]) == \"nan\":\n",
    "                    del dirData[\"regiones\"][reg_name[index]][\"meses\"][mes]\n",
    "                    break\n",
    "\n",
    "            if len(toolTip_v[index]) > 0:\n",
    "\n",
    "                toolTip_values = [str(df[x].values[i])\n",
    "                                  for x in toolTip_v[index]]\n",
    "                tip = {}\n",
    "                #print(index, v_reg, i, df[v_reg].values[i])\n",
    "                data_value = repair_num(df[v_reg].values[i])\n",
    "\n",
    "                \"\"\"\n",
    "                try:\n",
    "                    data_value=float(df[v_reg].values[i])\n",
    "                except:\n",
    "                    \"Existe algun signo\"\n",
    "                    aux=\"\"\n",
    "                    for letra in str(df[v_reg].values[i]):\n",
    "                        if letra.isdigit():\n",
    "                            aux=aux+letra\n",
    "                        elif letra ==\".\":\n",
    "                            aux=aux+letra\n",
    "                            \n",
    "                    data_value=float(aux)\n",
    "                \n",
    "                \"\"\"\n",
    "\n",
    "                if str(data_value).lower() == \"nan\" :\n",
    "                    data_value = \"No Data\"\n",
    "                else:\n",
    "                    if data_value - int(data_value) > 0.0001:\n",
    "                        data_value = round(data_value, 1)\n",
    "                    else:\n",
    "                        data_value = int(data_value)\n",
    "                tip[variable_meaning[index]] = data_value\n",
    "\n",
    "                # add data to tooltipe\n",
    "\n",
    "                tip[\"Fecha: \"] = str(int(df[\"anio\"].values[i])) + \\\n",
    "                    \"/ \" + df[\"mesSTR\"].values[i]\n",
    "\n",
    "                for indexTool, name in enumerate(toolTip_mening[index]):\n",
    "                    if str(toolTip_values[indexTool]).lower() == \"nan\":\n",
    "                        tip[name] = \"-\"\n",
    "                    else:\n",
    "                        tip[name] = toolTip_values[indexTool]\n",
    "\n",
    "                dirData[\"regiones\"][reg_name[index]\n",
    "                                    ][\"meses\"][mes][\"tooltip\"] = tip\n",
    "            else:\n",
    "\n",
    "                tip = {}\n",
    "                data_value = repair_num(df[v_reg].values[i])\n",
    "                if str(data_value).lower() == \"nan\" :\n",
    "                    data_value = \"No Data\"\n",
    "                else:\n",
    "                    if data_value - int(data_value) > 0.0001:\n",
    "                        data_value = round(data_value, 1)\n",
    "                    else:\n",
    "                        data_value = int(data_value)\n",
    "                tip[variable_meaning[index]] = data_value\n",
    "\n",
    "                tip[\"Fecha: \"] = str(int(df[\"anio\"].values[i])) + \\\n",
    "                    \"/ \" + df[\"mesSTR\"].values[i]\n",
    "                \n",
    "                dirData[\"regiones\"][reg_name[index]\n",
    "                                    ][\"meses\"][mes][\"tooltip\"] = tip\n",
    "                #old\n",
    "                #dirData[\"regiones\"][reg_name[index]][\"meses\"][mes][\"tooltip\"] ={}\n",
    "        anioInit = anio\n",
    "\n",
    "    return listData\n",
    "\n",
    "## D. Creating image to download\n",
    "sns.set()\n",
    "def create_image(df, varible_v, variable_meaning, save_dir):\n",
    "    print(\"img\", varible_v, variable_meaning)\n",
    "    objetive_var = varible_v\n",
    "\n",
    "    plt.close()\n",
    "    plt.clf()\n",
    "    \n",
    "    df['date'] = df[\"Mes\"].map(str) + '-' + df[\"anio\"].map(str)\n",
    "    for value in df['date'] :\n",
    "        df['date'] = pd.to_datetime(\n",
    "        df['date'], format='%m-%Y').dt.strftime('%m-%Y')\n",
    "\n",
    "    date = []\n",
    "    val = []\n",
    "    for i, value in enumerate(df[objetive_var]):\n",
    "        if str(value) == \"nan\":\n",
    "            continue\n",
    "        else:\n",
    "            value = repair_num(value)\n",
    "            val.append(value)\n",
    "            print((df['date'].values[i]))\n",
    "            date.append(df['date'].values[i])\n",
    "\n",
    "    df = pd.DataFrame(columns=['date', objetive_var])\n",
    "    df['date'] = date\n",
    "    df[objetive_var] = val\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.set_style(\"darkgrid\")\n",
    "\n",
    "    print(len(df['date']), len(df[objetive_var]))\n",
    "\n",
    "    ax = sns.lineplot(x=range(0, len(df['date'])), y=df[objetive_var])\n",
    "\n",
    "    \"\"\"\n",
    "    max_xticks = 11\n",
    "    xloc = plt.MaxNLocator(max_xticks)\n",
    "    print(xloc)\n",
    "    ax.xaxis.set_major_locator(xloc)\n",
    "    \"\"\"\n",
    "\n",
    "    names = []\n",
    "    print(len(df['date']))\n",
    "\n",
    "    ran = int((len(df['date'])+.5)/10)\n",
    "    if ran == 0:\n",
    "        ran = 1\n",
    "    if len(df['date']) / ran < 10:\n",
    "        ran = 1\n",
    "    names = [df['date'].values[d] for d in range(0, len(df['date']), ran)]\n",
    "    ticklabels = names\n",
    "    ax.set_xticks(range(0, len(df['date'])+1, ran))\n",
    "    ax.set_xticklabels(ticklabels)\n",
    "    fig.autofmt_xdate()\n",
    "    plt.title(variable_meaning)\n",
    "    plt.ylabel(variable_meaning)\n",
    "    plt.savefig(save_dir, dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "def naming_image(x):\n",
    "    return global_dir + \"/img/\" + init_data_name + x + '.png'\n",
    "\n",
    "def naming_file(y):\n",
    "    return global_dir + \"/\" + init_data_name + y + '.json'      \n",
    "    \n",
    "## E. Reading Data from API \n",
    "file = 'Innovacion.xlsx'\n",
    "global_dir = \"./data\"\n",
    "norm = False  # no normalizada\n",
    "init_data_name=\"Inov_\"\n",
    "link_data = \"https://smartdata-demo.sfo2.digitaloceanspaces.com/data/Innovacion.xlsx\"\n",
    "link_img = \"https://smartdata-demo.sfo2.digitaloceanspaces.com/data/img/\"\n",
    "link_glosario=\"https://smartdata-demo.sfo2.digitaloceanspaces.com/data/\"\n",
    "info_header=[ {\"titulo\":None,\"Fuente\":None, \"LinkDatosOriginales\":None, \n",
    "               \"comment\":None, \"linkPlot\":None,\"glosario\":None}]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Inov_01_Tasa_inn.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_01_Tasa_inn.json\n"
     ]
    }
   ],
   "source": [
    "sheetname =\"TasaInnovacion\"\n",
    "full_file_name = '01_Tasa_inn'\n",
    "info_header[0][\"titulo\"] = \"Tasa de Innovaci√≥n en la Industria de la Construcci√≥n\"\n",
    "info_header[0][\"Fuente\"] = \"Encuesta innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] = \"Tasa de Innovaci√≥n considera las empresas del sector que innovaron en los a√±os correspondientes a los datos de la Encuesta de Innovaci√≥n del Ministerio de Econom√≠a, Fomento y Turismo. La encuesta 2016 representa el levantamiento de datos de a√±os 2014 y 2015\"\n",
    "info_header[0][\"linkPlot\"] =\"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == \"TasaInnovacion\":\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    data = [[\"INOVARON\"]]\n",
    "    dataCorto = [[\"INOVARON [%]\"]]\n",
    "\n",
    "    for index, lista in enumerate(data):\n",
    "        toolTip_v = [[]]\n",
    "        toolTip_mening = [[]]\n",
    "        reg_name = [\"PAIS\"]\n",
    "        for index2, varname in enumerate(lista):\n",
    "            if index2 == 0:\n",
    "                varible_v = [varname]\n",
    "                variable_meaning = [dataCorto[index][index2]]\n",
    "            else:\n",
    "                toolTip_v[0].append(varname)\n",
    "                toolTip_mening[0].append(dataCorto[index][index2])\n",
    "                \n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening, norm)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Inov_02_gasto_inn.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_02_gasto_inn.json\n"
     ]
    }
   ],
   "source": [
    "sheetname =\"GastoInnovacion\"\n",
    "full_file_name = '02_gasto_inn'\n",
    "info_header[0][\"titulo\"] = \"Gasto en Innovaci√≥n en relaci√≥n a las ventas sector construcci√≥n\"\n",
    "info_header[0][\"Fuente\"] = \"Encuesta innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] = \"Considere los gastos declarados por las empresas en cuanto a innovaci√≥n sobre sus ventas. Fuente Encuesta de Innovaci√≥n del Ministerio de Econom√≠a, Fomento y Turismo. La encuesta 2016 representa el levantamiento de datos de a√±os 2014 y 2015\"\n",
    "info_header[0][\"linkPlot\"] =\"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == \"GastoInnovacion\":\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    data = [[\"Porc inovacion\"]]\n",
    "    dataCorto = [[\"Gasto [%]\"]]\n",
    "    for index, lista in enumerate(data):\n",
    "        toolTip_v = [[]]\n",
    "        toolTip_mening = [[]]\n",
    "        reg_name = [\"PAIS\"]\n",
    "        for index2, varname in enumerate(lista):\n",
    "            if index2 == 0:\n",
    "                varible_v = [varname]\n",
    "                variable_meaning = [dataCorto[index][index2]]\n",
    "            else:\n",
    "                toolTip_v[0].append(varname)\n",
    "                toolTip_mening[0].append(dataCorto[index][index2])\n",
    "                \n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening, norm)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Inov_03_Cont_inn.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_03_Cont_inn.json\n"
     ]
    }
   ],
   "source": [
    "sheetname = 'Porc_empresas_que_innovan'\n",
    "full_file_name = '03_Cont_inn'\n",
    "info_header[0][\"titulo\"] = \"Continuidad de la Innovaci√≥n\"\n",
    "info_header[0][\"Fuente\"] = \"Encuenta Innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] = \"Se consideran el tipo de innovaci√≥n como continua u ocasional, considerando las empresas que contestaron la encuesta (siempre asociadas a la construcci√≥n). Fuente: Encuesta de Innovaci√≥n del Ministerio de Econom√≠a, Fomento y Turismo.\"\n",
    "info_header[0][\"linkPlot\"] = \"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == 'Porc_empresas_que_innovan':\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    varible_v = [\"Grande_Porc\",\"mediana_Porc\",\"peque√±a_Porc\"]\n",
    "    variable_meaning = [\"Grande [%]\",\"Mediana[%]\",\"Peque√±a[%]\" ]\n",
    "    reg_name = [\"Grande\",\"Mediana\",\"Peque√±a\" ]\n",
    "    toolTip_v = [[],[],[]]\n",
    "    toolTip_mening =[[],[],[]]\n",
    "\n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Inov_04_Nota_Costos.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_04_Nota_Costos.json\n"
     ]
    }
   ],
   "source": [
    "sheetname =\"Nota Factores innovacion\"\n",
    "full_file_name = '04_Nota_Costos'\n",
    "info_header[0][\"titulo\"] = \"Nota Costos\"\n",
    "info_header[0][\"Fuente\"] = \"Encuesta innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] = info_header[0][\"titulo\"] \n",
    "info_header[0][\"linkPlot\"] =\"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == \"Nota Factores innovacion\":\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    data = [[\"Nota Costos\"]]\n",
    "    dataCorto = [[\"Nota Costos\"]]\n",
    "    for index, lista in enumerate(data):\n",
    "        toolTip_v = [[]]\n",
    "        toolTip_mening = [[]]\n",
    "        reg_name = [\"PAIS\"]\n",
    "        for index2, varname in enumerate(lista):\n",
    "            if index2 == 0:\n",
    "                varible_v = [varname]\n",
    "                variable_meaning = [dataCorto[index][index2]]\n",
    "            else:\n",
    "                toolTip_v[0].append(varname)\n",
    "                toolTip_mening[0].append(dataCorto[index][index2])\n",
    "                \n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening, norm)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Inov_05_Nota_conocimiento.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_05_Nota_conocimiento.json\n"
     ]
    }
   ],
   "source": [
    "sheetname =\"Nota Factores innovacion\"\n",
    "full_file_name = '05_Nota_conocimiento'\n",
    "info_header[0][\"titulo\"] = \"Nota Conocimiento\"\n",
    "info_header[0][\"Fuente\"] = \"Encuesta innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] =info_header[0][\"titulo\"] \n",
    "info_header[0][\"linkPlot\"] = \"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == \"Nota Factores innovacion\":\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    data = [[\"Nota conocimiento\"]]\n",
    "    dataCorto = [[\"Nota Conocimiento\"]]\n",
    "    for index, lista in enumerate(data):\n",
    "        toolTip_v = [[]]\n",
    "        toolTip_mening = [[]]\n",
    "        reg_name = [\"PAIS\"]\n",
    "        for index2, varname in enumerate(lista):\n",
    "            if index2 == 0:\n",
    "                # Nombre de la variable\n",
    "                varible_v = [varname]\n",
    "                variable_meaning = [dataCorto[index][index2]]\n",
    "            else:\n",
    "                toolTip_v[0].append(varname)\n",
    "                toolTip_mening[0].append(dataCorto[index][index2])\n",
    "                \n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening, norm)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) Inov_06_Nota_Mercado.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_06_Nota_Mercado.json\n"
     ]
    }
   ],
   "source": [
    "sheetname =\"Nota Factores innovacion\"\n",
    "full_file_name = '06_Nota_Mercado'\n",
    "info_header[0][\"titulo\"] = \"Nota Mercado\"\n",
    "info_header[0][\"Fuente\"] = \"Encuesta innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] =info_header[0][\"titulo\"] \n",
    "info_header[0][\"linkPlot\"] = \"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == \"Nota Factores innovacion\":\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    data = [[\"Nota Mercado\"]]\n",
    "    dataCorto = [[\"Nota Mercado\"]]\n",
    "    for index, lista in enumerate(data):\n",
    "        toolTip_v = [[]]\n",
    "        toolTip_mening = [[]]\n",
    "        reg_name = [\"PAIS\"]\n",
    "        for index2, varname in enumerate(lista):\n",
    "            if index2 == 0:\n",
    "                # Nombre de la variable\n",
    "                varible_v = [varname]\n",
    "                variable_meaning = [dataCorto[index][index2]]\n",
    "            else:\n",
    "                toolTip_v[0].append(varname)\n",
    "                toolTip_mening[0].append(dataCorto[index][index2])\n",
    "                \n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening, norm)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) Inov_07_Nota_otros_factores.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_07_Nota_otros_factores.json\n"
     ]
    }
   ],
   "source": [
    "sheetname =\"Nota Factores innovacion\"\n",
    "full_file_name = '07_Nota_otros_factores'\n",
    "info_header[0][\"titulo\"] = \"Nota Mercado: Otros Factores\"\n",
    "info_header[0][\"Fuente\"] = \"Encuesta innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] =info_header[0][\"titulo\"] \n",
    "info_header[0][\"linkPlot\"] = \"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == \"Nota Factores innovacion\":\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    data = [[\"Nota Otros\"]]\n",
    "    dataCorto = [[\"Nota Otros\"]]\n",
    "    for index, lista in enumerate(data):\n",
    "        toolTip_v = [[]]\n",
    "        toolTip_mening = [[]]\n",
    "        reg_name = [\"PAIS\"]\n",
    "        for index2, varname in enumerate(lista):\n",
    "            if index2 == 0:\n",
    "                varible_v = [varname]\n",
    "                variable_meaning = [dataCorto[index][index2]]\n",
    "            else:\n",
    "                toolTip_v[0].append(varname)\n",
    "                toolTip_mening[0].append(dataCorto[index][index2])\n",
    "                \n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening, norm)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8) Inov_08_Inn_futura2.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_08_Inn_futura2.json\n"
     ]
    }
   ],
   "source": [
    "sheetname =\"InovacionFutura\"\n",
    "full_file_name = '08_Inn_futura2'\n",
    "info_header[0][\"titulo\"] = \"Predisposici√≥n a innovar en 2 a√±os\"\n",
    "info_header[0][\"Fuente\"] = \"Encuesta innovaci√≥n\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] = \"Predisposici√≥n de las empresas a innovar en 2 a√±os m√°s. Fuente: Encuesta de Innovaci√≥n\"\n",
    "info_header[0][\"linkPlot\"] =\"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == \"InovacionFutura\":\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    data = [[\"Inovacion futura\"]]\n",
    "    dataCorto = [[\"Inovacion futura\"]]\n",
    "    for index, lista in enumerate(data):\n",
    "        toolTip_v = [[]]\n",
    "        toolTip_mening = [[]]\n",
    "        reg_name = [\"PAIS\"]\n",
    "        for index2, varname in enumerate(lista):\n",
    "            if index2 == 0:\n",
    "                varible_v = [varname]\n",
    "                variable_meaning = [dataCorto[index][index2]]\n",
    "            else:\n",
    "                toolTip_v[0].append(varname)\n",
    "                toolTip_mening[0].append(dataCorto[index][index2])\n",
    "                \n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening, norm)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9) Inov_09_Bim_inst.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_09_Bim_inst.json\n"
     ]
    }
   ],
   "source": [
    "sheetname = 'Intitucion'\n",
    "file='BIM.xlsx'\n",
    "full_file_name = '09_Bim_inst'\n",
    "info_header[0][\"titulo\"] = \"Instituciones con capacitaci√≥n formal de BIM por tipo de instituci√≥n y nivel de carrera\"\n",
    "info_header[0][\"Fuente\"] = \"PlanBIM\"\n",
    "info_header[0][\"LinkDatosOriginales\"] = link_data\n",
    "info_header[0][\"comment\"] = \"Cantidad de carreras que con formaci√≥n profesional BIM por tipo de instituci√≥n y nivel de carrera. Fuente: Plan BIM\"\n",
    "info_header[0][\"linkPlot\"] = \"\"\n",
    "info_header[0][\"glosario\"] = \"\"\n",
    "\n",
    "if sheetname == 'Intitucion':\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    varible_v = [ 'total','Universidades Privadas ',\n",
    "       'Universidades Estatales', 'Institutos Profesionales',\n",
    "       'Centros de Formaci√≥n T√©cnica', 'Empresas']\n",
    "    variable_meaning = [\"total\" ,\"U. Privadas\",\"U. Estatales\",\"Inst. Prof.\",\n",
    "        \"Form. T√©cnica\",\"Empresas\"]\n",
    "    reg_name = [\"total\" ,\"U. Privadas\",\"U. Estatales\",\"Inst. Prof.\",\n",
    "        \"Form. T√©cnica\",\"Empresas\"]\n",
    "    toolTip_v = [[\"var_total\"],\n",
    "    ['var_Universidades Privadas '],\n",
    "    [\"var_Universidades Estatales\"],\n",
    "    [\"var_Institutos Profesionales\"],\n",
    "    [\"var_Centros de Formaci√≥n T√©cnica\"],\n",
    "    [\"var_Empresas\"]]\n",
    "    toolTip_mening =[[\"Var Anual\"],[\"Var Anual\"],[\"Var Anual\"],\n",
    "                    [\"Var Anual\"],[\"Var Anual\"],[\"Var Anual\"]]\n",
    "\n",
    "\n",
    "    jsonDir = DataToJson(df, varible_v, variable_meaning,reg_name, toolTip_v, toolTip_mening)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10) Inov_10_Bim_inst_region.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set: None\n",
      "CREATED:  ./data/Inov_10_Bim_inst_region.json\n"
     ]
    }
   ],
   "source": [
    "sheetname = 'region'\n",
    "file='BIM.xlsx'\n",
    "full_file_name = '10_Bim_inst_region'\n",
    "info_header[0][\"titulo\"]= \"Instituciones con capacitaci√≥n formal de BIM por tipo de instituci√≥n y regi√≥n\"\n",
    "info_header[0][\"Fuente\"]=\"ENCUESTA BIM\"\n",
    "info_header[0][\"LinkDatosOriginales\"]=link_data\n",
    "info_header[0][\"comment\"]= \"Cantidad de carreras que con formaci√≥n profesional BIM por tipo de instituci√≥n y regi√≥n. Fuente: Plan BIM\"\n",
    "info_header[0][\"linkPlot\"]=\"\"\n",
    "info_header[0][\"glosario\"]=link_glosario+\"general.pdf\"\n",
    "\n",
    "if sheetname == 'region':\n",
    "    df = pd.read_excel(file, sheet_name=sheetname)\n",
    "    varible_v=[\"Total general\" ]*18\n",
    "    variable_meaning=[\"Total general\" ]*18\n",
    "    reg_name=[\n",
    "    \"REGI√ìN BIO BIO\",\n",
    "    \"REGI√ìN DE AIS√âN\",\n",
    "    \"REGI√ìN DE ANTOFAGASTA\",\n",
    "    \"REGI√ìN DE ARICA Y PARINACOTA\",\n",
    "    \"REGI√ìN DE COQUIMBO\",\n",
    "    \"REGI√ìN DE LA ARAUCAN√çA\",\n",
    "    \"REGI√ìN DE LOS LAGOS\",\n",
    "    \"REGI√ìN DE LOS R√çOS\",\n",
    "    \"REGI√ìN DE MAGALLANES Y ANT√ÅRTICA CHILENA\",\n",
    "    \"REGI√ìN DE √ëUBLE\",\n",
    "    \"REGI√ìN DE TARAPAC√Å\",\n",
    "    \"REGI√ìN DE VALPARA√çSO\",\n",
    "    \"REGI√ìN DEL BIO BIO\",\n",
    "    \"REGI√ìN DEL MAULE\",\n",
    "    \"REGI√ìN LIBERTADOR GENERAL BERNARDO O'HIGGINS\",\n",
    "    \"REGI√ìN METROPOLITANA\",\n",
    "    \"REGI√ìON DEL MAULE\",\n",
    "    \"REGI√ìN DE ATACAMA\",\n",
    "    ]\n",
    "\n",
    "    toolTip_v=[[\"Postgrado\",\t\"Post√≠tulo\",\t\"Pregrado\"]]*18\n",
    "    toolTip_mening=[[\"Postgrado\",\t\"Post√≠tulo\",\t\"Pregrado\"] ]*18\n",
    "\n",
    "    jsonDir = DataToJson(df,varible_v,variable_meaning,reg_name, toolTip_v, toolTip_mening)\n",
    "    jsonDir = [info_header, jsonDir]\n",
    "    jsonUTF8 = json.dumps(jsonDir, ensure_ascii=False).encode('utf8')\n",
    "    jsonUTF8 = json.loads(jsonUTF8)    \n",
    "#     create_image(df, varible_v[0], variable_meaning[0],naming_image(full_file_name))\n",
    "    name_file = naming_file(full_file_name)\n",
    "    with open(name_file , 'w') as outfile:  \n",
    "        json.dump(jsonUTF8, outfile,ensure_ascii=False)\n",
    "    print(\"CREATED: \", name_file)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
